library("tm")

filePath <- "C:\\Users\\goncalg4\\workplace\\old\\PythonScripts\\TelegramChatWordFrequency\\storage\\output_Chamys.txt"
text <- readLines(filePath, encoding="UTF-8")
docs <- Corpus(VectorSource(text))
inspect(docs)
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
docs <- tm_map(docs, toSpace, "/")
docs <- tm_map(docs, toSpace, "@")
docs <- tm_map(docs, toSpace, "\\|")
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, removeWords, stopwords("portuguese"))
docs <- tm_map(docs, removeWords, c("tá", "ta", "pra", "tô", "to", "bem", "mete", "frente", "chegou", "joga", "vai", "vem", "assim", "pro", "vou", "desde", "fiz", "vim", "não", "nao", "logo", "entra", "hora", "muito", "cima", "sim", "ligado", "tchau", "música", "musica", "vários", "varios", "vão", "vao", "todas", "chora", "toma", "lá", "tomar", "som", "vamo", "ponta", "tomo", "sabe", "todo", "chama", "pura", "ver", "fazer", "pega", "falar", "fim", "passa", "tirando", "nada", "pois", "faz", "mim", "sei", "tambem", "jeito", "deu", "cada", "mó", "sao", "são", "nova", "moleque", "muleque", "gente", "pesado", "porque", "pouco", "forte", "problema", "lado", "entao", "daqui", "deu", "cada", "mó", "sao", "são", "nova", "moleque", "muleque", "gente", "pesado", "porque", "pouco", "forte", "problema", "lado", "entao", "daqui"))
docs <- tm_map(docs, removeWords, c("hrefhttps", "href", "https"))
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, stripWhitespace)

tdm <- TermDocumentMatrix(docs)
removeSparseTerms(tdm, .999)
m <- as.matrix(tdm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
write.csv(d,"C:\\Users\\goncalg4\\workplace\\old\\PythonScripts\\TelegramChatWordFrequency\\storage\\output_Chamys.csv", row.names = FALSE)
